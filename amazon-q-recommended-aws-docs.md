[
  {
    "url": "https://docs.aws.amazon.com/AWSJavaScriptSDK/v3/latest/client/ses/",
    "text": "AWS SDK for JavaScript v3\nYou are on a Client landing page. Commands (operations) are listed on this page. The Client constructor type is linked at the bottom. \nSESClient\nInstallation\nNPM\nnpm install @aws-sdk/client-ses\nYarn\nyarn add @aws-sdk/client-ses\npnpm\npnpm add @aws-sdk/client-ses\nAdditional config fields are described in the full configuration type: SESClientConfig"
  },
  {
    "url": "https://aws.amazon.com/blogs/architecture/exponential-backoff-and-jitter/",
    "text": "Select your cookie preferences\nWe use essential cookies and similar tools that are necessary to provide our site and services. We use performance cookies to collect anonymous statistics, so we can understand how customers use our site and make improvements. Essential cookies cannot be deactivated, but you can choose “Customize” or “Decline” to decline performance cookies. \n\nIf you agree, AWS and approved third parties will also use cookies to provide useful site features, remember your preferences, and display relevant content, including relevant advertising. To accept or decline all non-essential cookies, choose “Accept” or “Decline.” To make more detailed choices, choose “Customize.”\nAcceptDeclineCustomize\nSkip to Main Content \nAWS Architecture Blog\nExponential Backoff And Jitter\nUpdate (May 2023): After 8 years, this solution continues to serve as a pillar for how Amazon builds remote client libraries for resilient systems. Most AWS SDKs now support exponential backoff and jitter as part of their retry behavior when using standard or adaptive modes. Consequently, this pattern can be leveraged without having to incorporate personal logic around AWS SDK requests made to AWS services. The list of AWS SDKs that support these features can be found in the AWS SDK documentation.\nYou can also dive deeper into timeouts, retries, and backoff with jitter in our Amazon Builders’ Library.\nIntroducing OCC\nOptimistic concurrency control (OCC) is a time-honored way for multiple writers to safely modify a single object without losing writes. OCC has three nice properties: it will always make progress as long as the underlying store is available, it’s easy to understand, and it’s easy to implement. DynamoDB’s conditional writes make OCC a natural fit for DynamoDB users, and it’s natively supported by the DynamoDBMapper client.\nWhile OCC is guaranteed to make progress, it can still perform quite poorly under high contention. The simplest of these contention cases is when a whole lot of clients start at the same time, and try to update the same database row. With one client guaranteed to succeed every round, the time to complete all the updates grows linearly with contention.\nFor the graphs in this post, I used a small simulator to model the behavior of OCC on a network with delay (and variance in delay), against a remote database. In this simulation, the network introduces delay with a mean of 10ms and variance of 4ms. The first simulation shows how completion time grows linearly with contention. This linear growth is because one client succeeds every round, so it takes N rounds for all N clients to succeed.\nUnfortunately, that’s not the whole picture. With N clients contending, the total amount of work done by the system increases with N2.\nAdding Backoff\nThe problem here is that N clients compete in the first round, N-1 in the second round, and so on. Having every client compete in every round is wasteful. Slowing clients down may help, and the classic way to slow clients down is capped exponential backoff. Capped exponential backoff means that clients multiply their backoff by a constant after each attempt, up to some maximum value. In our case, after each unsuccessful attempt, clients sleep for:\nRunning the simulation again shows that backoff helps a small amount, but doesn’t solve the problem. Client work has only been reduced slightly.\nThe best way to see the problem is to look at the times these exponentially backed-off calls happen.\nIt’s obvious that the exponential backoff is working, in that the calls are happening less and less frequently. The problem also stands out: there are still clusters of calls. Instead of reducing the number of clients competing in every round, we’ve just introduced times when no client is competing. Contention hasn’t been reduced much, although the natural variance in network delay has introduced some spreading.\nAdding Jitter\nThe solution isn’t to remove backoff. It’s to add jitter. Initially, jitter may appear to be a counter-intuitive idea: trying to improve the performance of a system by adding randomness. The time series above makes a great case for jitter – we want to spread out the spikes to an approximately constant rate. Adding jitter is a small change to the sleep function:\nThat time series looks a whole lot better. The gaps are gone, and beyond the initial spike, there’s an approximately constant rate of calls. It’s also had a great effect on the total number of calls.\nIn the case with 100 contending clients, we’ve reduced our call count by more than half. We’ve also significantly improved the time to completion, when compared to un-jittered exponential backoff.\nThere are a few ways to implement these timed backoff loops. Let’s call the algorithm above “Full Jitter”, and consider two alternatives. The first alternative is “Equal Jitter”, where we always keep some of the backoff and jitter by a smaller amount:\nThe intuition behind this one is that it prevents very short sleeps, always keeping some of the slow down from the backoff. A second alternative is “Decorrelated Jitter”, which is similar to “Full Jitter”, but we also increase the maximum jitter based on the last random value.\nWhich approach do you think is best?\nLooking at the amount of client work, the number of calls is approximately the same for “Full” and “Equal” jitter, and higher for “Decorrelated”. Both cut down work substantially relative to both the no-jitter approaches.\nThe no-jitter exponential backoff approach is the clear loser. It not only takes more work, but also takes more time than the jittered approaches. In fact, it takes so much more time we have to leave it off the graph to get a good comparison of the other methods.\nOf the jittered approaches, “Equal Jitter” is the loser. It does slightly more work than “Full Jitter”, and takes much longer. The decision between “Decorrelated Jitter” and “Full Jitter” is less clear. The “Full Jitter” approach uses less work, but slightly more time. Both approaches, though, present a substantial decrease in client work and server load.\nIt’s worth noting that none of these approaches fundamentally change the N2 nature of the work to be done, but do substantially reduce work at reasonable levels of contention. The return on implementation complexity of using jittered backoff is huge, and it should be considered a standard approach for remote clients.\nAll of the graphs and numbers from this post were generated using a simple simulation of OCC behavior. You can get our simulator code on GitHub, in the aws-arch-backoff-simulator project.\nAWS Podcast \nSubscribe for weekly AWS news and interviews \nLearn more \nAWS Partner Network \nFind an APN member to support your cloud business needs \nLearn more \nAWS Training & Certifications \nFree digital courses to help you develop your skills \nLearn more \nResources\nAWS Architecture Center\nAWS Well-Architected\nAWS Architecture Monthly\nAWS Whitepapers\nAWS Training and Certification\nThis Is My Architecture\nFollow\nTwitter\nFacebook\nLinkedIn\nTwitch\nEmail Updates\nAWS Events \nDiscover the latest AWS events in your region \nLearn more \nCCBA-Footer"
  },
  {
    "url": "https://nextjs.org/docs/app/building-your-application/routing/route-handlers",
    "text": "Skip to content\nMenu\nUsing App Router\nFeatures available in /app\nLatest Version\n16.0.1\nUsing App Router\nFeatures available in /app\nLatest Version\n16.0.1\nAPI ReferenceFile-system conventionsroute.js\nCopy page\nroute.js\nRoute Handlers allow you to create custom request handlers for a given route using the Web Request and Response APIs.\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET() { return Response.json({ message: 'Hello World' }) }\nReference\nHTTP Methods\nA route file allows you to create custom request handlers for a given route. The following HTTP methods are supported: GET, POST, PUT, PATCH, DELETE, HEAD, and OPTIONS.\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(request: Request) {} export async function HEAD(request: Request) {} export async function POST(request: Request) {} export async function PUT(request: Request) {} export async function DELETE(request: Request) {} export async function PATCH(request: Request) {} // If `OPTIONS` is not defined, Next.js will automatically implement `OPTIONS` and set the appropriate Response `Allow` header depending on the other methods defined in the Route Handler. export async function OPTIONS(request: Request) {}\nParameters\nrequest (optional)\nThe request object is a NextRequest object, which is an extension of the Web Request API. NextRequest gives you further control over the incoming request, including easily accessing cookies and an extended, parsed, URL object nextUrl.\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport type { NextRequest } from 'next/server' export async function GET(request: NextRequest) { const url = request.nextUrl }\ncontext (optional)\nparams: a promise that resolves to an object containing the dynamic route parameters for the current route.\napp/dashboard/[team]/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET( request: Request, { params }: { params: Promise<{ team: string }> } ) { const { team } = await params }\nExampleURLparams\napp/dashboard/[team]/route.js\t/dashboard/1\tPromise<{ team: '1' }>\t\napp/shop/[tag]/[item]/route.js\t/shop/1/2\tPromise<{ tag: '1', item: '2' }>\t\napp/blog/[...slug]/route.js\t/blog/1/2\tPromise<{ slug: ['1', '2'] }>\t\nRoute Context Helper\nYou can type the Route Handler context using RouteContext to get strongly typed params from a route literal. RouteContext is a globally available helper.\napp/users/[id]/route.ts\nimport type { NextRequest } from 'next/server' export async function GET(_req: NextRequest, ctx: RouteContext<'/users/[id]'>) { const { id } = await ctx.params return Response.json({ id }) }\nGood to know\nTypes are generated during next dev, next build or next typegen.\nAfter type generation, the RouteContext helper is globally available. It doesn't need to be imported.\nExamples\nCookies\nYou can read or set cookies with cookies from next/headers.\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers' export async function GET(request: NextRequest) { const cookieStore = await cookies() const a = cookieStore.get('a') const b = cookieStore.set('b', '1') const c = cookieStore.delete('c') }\nAlternatively, you can return a new Response using the Set-Cookie header.\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { cookies } from 'next/headers' export async function GET(request: Request) { const cookieStore = await cookies() const token = cookieStore.get('token') return new Response('Hello, Next.js!', { status: 200, headers: { 'Set-Cookie': `token=${token.value}` }, }) }\nYou can also use the underlying Web APIs to read cookies from the request (NextRequest):\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server' export async function GET(request: NextRequest) { const token = request.cookies.get('token') }\nHeaders\nYou can read headers with headers from next/headers.\nroute.ts\nTypeScript\nJavaScript\nTypeScript\nimport { headers } from 'next/headers' import type { NextRequest } from 'next/server' export async function GET(request: NextRequest) { const headersList = await headers() const referer = headersList.get('referer') }\nThis headers instance is read-only. To set headers, you need to return a new Response with new headers.\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { headers } from 'next/headers' export async function GET(request: Request) { const headersList = await headers() const referer = headersList.get('referer') return new Response('Hello, Next.js!', { status: 200, headers: { referer: referer }, }) }\nYou can also use the underlying Web APIs to read headers from the request (NextRequest):\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server' export async function GET(request: NextRequest) { const requestHeaders = new Headers(request.headers) }\nRevalidating Cached Data\nYou can revalidate cached data using the revalidate route segment config option.\napp/posts/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const revalidate = 60 export async function GET() { const data = await fetch('https://api.vercel.app/blog') const posts = await data.json() return Response.json(posts) }\nRedirects\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { redirect } from 'next/navigation' export async function GET(request: Request) { redirect('https://nextjs.org/') }\nDynamic Route Segments\nRoute Handlers can use Dynamic Segments to create request handlers from dynamic data.\napp/items/[slug]/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET( request: Request, { params }: { params: Promise<{ slug: string }> } ) { const { slug } = await params // 'a', 'b', or 'c' }\nRouteExample URLparams\napp/items/[slug]/route.js\t/items/a\tPromise<{ slug: 'a' }>\t\napp/items/[slug]/route.js\t/items/b\tPromise<{ slug: 'b' }>\t\napp/items/[slug]/route.js\t/items/c\tPromise<{ slug: 'c' }>\t\nURL Query Parameters\nThe request object passed to the Route Handler is a NextRequest instance, which includes some additional convenience methods, such as those for more easily handling query parameters.\napp/api/search/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { type NextRequest } from 'next/server' export function GET(request: NextRequest) { const searchParams = request.nextUrl.searchParams const query = searchParams.get('query') // query is \"hello\" for /api/search?query=hello }\nStreaming\nStreaming is commonly used in combination with Large Language Models (LLMs), such as OpenAI, for AI-generated content. Learn more about the AI SDK.\napp/api/chat/route.ts\nTypeScript\nJavaScript\nTypeScript\nimport { openai } from '@ai-sdk/openai' import { StreamingTextResponse, streamText } from 'ai' export async function POST(req: Request) { const { messages } = await req.json() const result = await streamText({ model: openai('gpt-4-turbo'), messages, }) return new StreamingTextResponse(result.toAIStream()) }\nThese abstractions use the Web APIs to create a stream. You can also use the underlying Web APIs directly.\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\n// https://developer.mozilla.org/docs/Web/API/ReadableStream#convert_async_iterator_to_stream function iteratorToStream(iterator: any) { return new ReadableStream({ async pull(controller) { const { value, done } = await iterator.next() if (done) { controller.close() } else { controller.enqueue(value) } }, }) } function sleep(time: number) { return new Promise((resolve) => { setTimeout(resolve, time) }) } const encoder = new TextEncoder() async function* makeIterator() { yield encoder.encode('<p>One</p>') await sleep(200) yield encoder.encode('<p>Two</p>') await sleep(200) yield encoder.encode('<p>Three</p>') } export async function GET() { const iterator = makeIterator() const stream = iteratorToStream(iterator) return new Response(stream) }\nRequest Body\nYou can read the Request body using the standard Web API methods:\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) { const res = await request.json() return Response.json({ res }) }\nRequest Body FormData\nYou can read the FormData using the request.formData() function:\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) { const formData = await request.formData() const name = formData.get('name') const email = formData.get('email') return Response.json({ name, email }) }\nSince formData data are all strings, you may want to use zod-form-data to validate the request and retrieve data in the format you prefer (e.g. number).\nCORS\nYou can set CORS headers for a specific Route Handler using the standard Web API methods:\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET(request: Request) { return new Response('Hello, Next.js!', { status: 200, headers: { 'Access-Control-Allow-Origin': '*', 'Access-Control-Allow-Methods': 'GET, POST, PUT, DELETE, OPTIONS', 'Access-Control-Allow-Headers': 'Content-Type, Authorization', }, }) }\nGood to know:\nTo add CORS headers to multiple Route Handlers, you can use Proxy or the next.config.js file.\nWebhooks\nYou can use a Route Handler to receive webhooks from third-party services:\napp/api/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function POST(request: Request) { try { const text = await request.text() // Process the webhook payload } catch (error) { return new Response(`Webhook error: ${error.message}`, { status: 400, }) } return new Response('Success!', { status: 200, }) }\nNotably, unlike API Routes with the Pages Router, you do not need to use bodyParser to use any additional configuration.\nNon-UI Responses\nYou can use Route Handlers to return non-UI content. Note that sitemap.xml, robots.txt, app icons, and open graph images all have built-in support.\napp/rss.xml/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport async function GET() { return new Response( `<?xml version=\"1.0\" encoding=\"UTF-8\" ?> <rss version=\"2.0\"> <channel> <title>Next.js Documentation</title> <link>https://nextjs.org/docs</link> <description>The React Framework for the Web</description> </channel> </rss>`, { headers: { 'Content-Type': 'text/xml', }, } ) }\nSegment Config Options\nRoute Handlers use the same route segment configuration as pages and layouts.\napp/items/route.ts\nTypeScript\nJavaScript\nTypeScript\nexport const dynamic = 'auto' export const dynamicParams = true export const revalidate = false export const fetchCache = 'auto' export const runtime = 'nodejs' export const preferredRegion = 'auto'\nSee the API reference for more details.\nVersion History\nVersionChanges\nv15.0.0-RC\tcontext.params is now a promise. A codemod is available\t\nv15.0.0-RC\tThe default caching for GET handlers was changed from static to dynamic\t\nv13.2.0\tRoute Handlers are introduced.\t\nWas this helpful?\nsupported.\nSend\nView as MarkdownOpen this page in Markdown\nOpen in v0Ask questions about this page\nOpen in ClaudeAsk questions about this page\nOpen in ChatGPTAsk questions about this page\nUsing App Router\nFeatures available in /app\nUsing Pages Router\nFeatures available in /pages\nLatest\n16.0.1\nVersion 15\n15.5.6\nVersion 14\n14.2.33\nVersion 13\n13.5.11\nUsing App Router\nFeatures available in /app\nUsing Pages Router\nFeatures available in /pages\nLatest\n16.0.1\nVersion 15\n15.5.6\nVersion 14\n14.2.33\nVersion 13\n13.5.11"
  }
]